import re
import gradio as gr
from openai import OpenAI
from fileParser import FileParser
from API import DEEPSEEK_API_KEY, DEEPSEEK_API_URL
from static import SYSPROMPT

def save_sysprompt_to_file(sys_prompt_text):
    file_path = "static.py"
    
    # è¯»å– static.py å†…å®¹
    with open(file_path, "r", encoding="utf-8") as f:
        content = f.read()
    
    # æ›¿æ¢ SYSPROMPT çš„å€¼
    new_content = re.sub(
        r'SYSPROMPT\s*=\s*("""|\'\'\')(.*?)(\1)',
        f'SYSPROMPT = """{sys_prompt_text}"""',
        content,
        flags=re.DOTALL
    )
    
    # å†™å› static.py
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(new_content)
    
    return "ç³»ç»Ÿæç¤ºè¯å·²å­˜æ¡£ï¼"


# æŸ¥è¯¢ æœ¬åœ°å¤§æ¨¡å‹
def query_gpt4all(sys_prompt, user_text, file_path):
    client = OpenAI(api_key="ollama", base_url="http://localhost:11434/v1")
    content = FileParser(file_path).extract_text()
    response = client.chat.completions.create(
        model="llama3-8b-instruct",
        messages=[
            {"role": "system", "content": sys_prompt},
            {"role": "user", "content": user_text },
        ],
        stream=False
    )
    content = response.choices[0].message.content
    return content

# æ›´æ–°ç³»ç»Ÿæç¤ºè¯
def updateSysprompt(input):
    sys_prompt = input
    return sys_prompt

# æ ¹æ®ç”¨æˆ·åé¦ˆè‡ªåŠ¨ç”Ÿæˆæ–°çš„ç³»ç»Ÿæç¤ºè¯
def generate_sys_prompt_from_feedback(original_sys_prompt, feedback):
    client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_API_URL)
    response = client.chat.completions.create(
        model="deepseek-reasoner",
        messages=[
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªpromptå·¥ç¨‹ä¸“å®¶ï¼Œç”¨æˆ·å°†ç»™ä½ ä¸€ä¸ªå½“å‰çš„ç³»ç»Ÿæç¤ºè¯å’Œä¸€æ®µåé¦ˆï¼Œè¯·ä½ è¾“å‡ºä¸€ä¸ªæ›´å¥½çš„ç³»ç»Ÿæç¤ºè¯ã€‚"},
            {"role": "user", "content": f"åŸç³»ç»Ÿæç¤ºè¯å¦‚ä¸‹ï¼š\n{original_sys_prompt}\n\nç”¨æˆ·åé¦ˆå¦‚ä¸‹ï¼š\n{feedback}\n\nè¯·ä½ åŸºäºè¿™äº›ç”Ÿæˆä¸€ä¸ªæ–°çš„ç³»ç»Ÿæç¤ºè¯ï¼Œå°½é‡æ»¡è¶³ç”¨æˆ·çš„æ„å›¾ã€‚"},
        ],
        stream=False
    )
    new_prompt = response.choices[0].message.content
    return new_prompt

with gr.Blocks() as demo:
    gr.Markdown("## DeepSeek æŸ¥è¯¢ GUI")

    with gr.Row():
        with gr.Column(scale=1):
            latest_sys_prompt = gr.Textbox(label="å½“å‰ç³»ç»Ÿæç¤ºè¯", value=SYSPROMPT, interactive=False, lines=18, min_width=100)
            save_button = gr.Button("å­˜æ¡£ç³»ç»Ÿæç¤ºè¯")

        with gr.Column(scale=1):
            sys_prompt = gr.Textbox(label="ä¿®æ”¹ç³»ç»Ÿæç¤ºè¯", placeholder="è¾“å…¥è¦æ›´æ–°çš„ç³»ç»Ÿæç¤ºè¯", lines=18, min_width=300)
            update_button = gr.Button("æ›´æ–°ç³»ç»Ÿæç¤ºè¯")

        with gr.Column(scale=1):
            user_input = gr.Textbox(label="è¾“å…¥æ–‡æœ¬", placeholder="åœ¨è¿™é‡Œè¾“å…¥æŸ¥è¯¢æ–‡æœ¬", lines=18, min_width=300)
            run_button = gr.Button("æŸ¥è¯¢")

    file_input = gr.File(label="æ‹–æ‹½æ–‡ä»¶ä¸Šä¼ ", file_types=[".xlsx", ".xls", ".csv", ".pdf"], min_width=100, elem_id="file-box")

    with gr.Row():
        with gr.Column(scale=1):
            result_output = gr.Textbox(label="æœ€ç»ˆç»“æœ", lines=24)

    # ç”¨æˆ·åé¦ˆéƒ¨åˆ†
    gr.Markdown("### ğŸ“ å¯¹å½“å‰è¾“å‡ºç»“æœçš„åé¦ˆ")
    feedback_input = gr.Textbox(label="è¯·è¾“å…¥ä½ å¯¹å½“å‰è¾“å‡ºçš„åé¦ˆ", placeholder="ä¾‹å¦‚ï¼šç»“æœä¸å¤Ÿè¯¦ç»† / æƒ³æ›´ä¸“ä¸š / æƒ³æ›´å£è¯­åŒ–", lines=5)
    gen_prompt_button = gr.Button("æ ¹æ®åé¦ˆç”Ÿæˆæ–°çš„ç³»ç»Ÿæç¤ºè¯")

    # ç»‘å®šäº‹ä»¶
    update_button.click(
        updateSysprompt, 
        inputs=sys_prompt, 
        outputs=[latest_sys_prompt] 
    )

    run_button.click(
        query_gpt4all, 
        inputs=[latest_sys_prompt, user_input, file_input], 
        outputs=[result_output]
    )

    gen_prompt_button.click(
        generate_sys_prompt_from_feedback,
        inputs=[sys_prompt, feedback_input],
        outputs=[latest_sys_prompt] 
    )

    save_button.click(
    save_sysprompt_to_file,
    inputs=latest_sys_prompt,
    )

    demo.launch(share=True)